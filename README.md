<center>
<img src="xgboost2.JPG">

### Table of Contents:
1. Goals and final targets definition
2. Data preparation for modeling, various models and encoding technique	analysis:
   - Features with NaN values analysis
   - Dealing with categorical features
   - Cross validation strategy
   - Various models and encoding technique analysis
   - Final panel preparation for the model
3. Models comparison:
   - Models evaluation prior implementing a cross validation: Accuracy and log loss 
   - Models evaluation using a cross validation: Accuracy, Log loss, Recall, Precision, F-score and AUC
4. Learning Curves:
   - Train data errors vs Cross validation errors
   - Accuracy vs Number of trees and max depth 
5. Explore the model in order to improve the results:
   - Hyperparameters tuning and optimization
   - Early stop strategy
6. Confusion matrix and threshhold tuning
7. Effort to improve the results-Stacking implementation

- [**XGBoost project - binary classification and regression models**](https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html) - Using mortality data from 20 years of followup this notebook demonstrates how to use XGBoost and `shap` to uncover complex risk factor relationships.
